# ConfiguraciÃ³n de Ollama para el Chatbot IA

## ğŸš€ InstalaciÃ³n de Ollama

### Windows (WSL2 recomendado)
```bash
# Instalar WSL2 si no lo tienes
wsl --install

# En WSL2, ejecutar:
curl -fsSL https://ollama.ai/install.sh | sh

# O descargar desde: https://ollama.ai/download
```

### macOS
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### Linux
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

## ğŸ“¥ Descargar Modelos

### Modelo recomendado para anÃ¡lisis de textos:
```bash
# Llama 2 (7B parÃ¡metros - buen balance)
ollama pull llama2

# O Mistral (muy bueno para espaÃ±ol)
ollama pull mistral

# O Phi-2 (mÃ¡s pequeÃ±o, rÃ¡pido)
ollama pull phi
```

## ğŸƒâ€â™‚ï¸ Ejecutar Ollama

```bash
# Iniciar el servicio
ollama serve

# En otra terminal, probar el modelo
ollama run llama2
```

## ğŸ”§ ConfiguraciÃ³n del Chatbot

El chatbot estÃ¡ configurado para conectarse a:
- **URL**: `http://localhost:11434/api/generate`
- **Modelo por defecto**: `llama2`
- **Puerto**: `11434` (puerto por defecto de Ollama)

## ğŸ§ª Probar la ConexiÃ³n

### 1. Verificar que Ollama estÃ© ejecutÃ¡ndose:
```bash
curl http://localhost:11434/api/tags
```

### 2. Probar una consulta simple:
```bash
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama2",
    "prompt": "Hola, Â¿cÃ³mo estÃ¡s?",
    "stream": false
  }'
```

## ğŸ¯ Funcionalidades del Chatbot

### AnÃ¡lisis de Textos AcadÃ©micos:
- âœ… CorrecciÃ³n gramatical y ortogrÃ¡fica
- âœ… AnÃ¡lisis de estructura y coherencia
- âœ… Sugerencias de mejora
- âœ… Feedback especÃ­fico para prospectiva
- âœ… PuntuaciÃ³n del 1 al 10

### Casos de Uso:
- ğŸ“ **Ensayos**: CorrecciÃ³n y anÃ¡lisis de estructura
- ğŸ”¬ **Trabajos cientÃ­ficos**: RevisiÃ³n de metodologÃ­a
- ğŸ’» **CÃ³digo**: AnÃ¡lisis de lÃ³gica y buenas prÃ¡cticas
- ğŸ“Š **AnÃ¡lisis prospectivo**: EvaluaciÃ³n de variables y escenarios

## âš™ï¸ PersonalizaciÃ³n

### Cambiar el modelo en el componente:
Editar `resources/js/components/app/ui/FloatingChatbotComponent.vue`:

```javascript
// LÃ­nea 150 - cambiar el modelo
model: 'mistral', // en lugar de 'llama2'
```

### Ajustar parÃ¡metros:
```javascript
options: {
  temperature: 0.7,    // Creatividad (0-1)
  top_p: 0.9,         // Diversidad
  max_tokens: 1000    // Longitud mÃ¡xima
}
```

## ğŸš¨ SoluciÃ³n de Problemas

### Error: "Connection refused"
- Verificar que Ollama estÃ© ejecutÃ¡ndose: `ollama serve`
- Comprobar el puerto: `netstat -an | grep 11434`

### Error: "Model not found"
- Descargar el modelo: `ollama pull llama2`
- Verificar modelos disponibles: `ollama list`

### Error: "Out of memory"
- Usar un modelo mÃ¡s pequeÃ±o: `ollama pull phi`
- Aumentar la RAM disponible para WSL2

## ğŸ“± Uso en la AplicaciÃ³n

1. **Abrir el chatbot**: Hacer clic en el botÃ³n flotante (robot)
2. **Escribir texto**: Enviar el texto a analizar
3. **Recibir feedback**: La IA proporcionarÃ¡ anÃ¡lisis detallado
4. **Cerrar**: Hacer clic en el botÃ³n de cerrar o en el robot

## ğŸ”’ Privacidad

- âœ… **100% local**: Los textos nunca salen de tu servidor
- âœ… **Sin lÃ­mites**: Sin costos por token
- âœ… **Sin registro**: No necesitas cuentas externas
- âœ… **Datos seguros**: Perfecto para contenido acadÃ©mico

## ğŸ“ˆ Rendimiento

### Requisitos mÃ­nimos:
- **RAM**: 8GB (16GB recomendado)
- **CPU**: 4 cores
- **Almacenamiento**: 5GB para modelos

### Tiempos de respuesta:
- **Llama 2**: ~2-5 segundos
- **Mistral**: ~1-3 segundos
- **Phi-2**: ~1-2 segundos

## ğŸ¨ PersonalizaciÃ³n Visual

El chatbot incluye:
- ğŸ¨ DiseÃ±o moderno con gradientes
- ğŸ“± Responsive para mÃ³viles
- âš¡ Animaciones suaves
- ğŸ¯ Indicador de escritura
- ğŸ“… Timestamps en mensajes 